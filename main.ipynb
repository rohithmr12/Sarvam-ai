{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: llama-index in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.11.10)\n",
      "Requirement already satisfied: unstructured in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.12.6)\n",
      "Requirement already satisfied: openai in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (1.46.1)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.2.11)\n",
      "Requirement already satisfied: pypdf in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.3.3)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.10 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.11.10)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.2.5)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.9.48.post3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.2.9)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.2.1)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.2.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.3.0)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: backoff==2.2.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (4.12.3)\n",
      "Requirement already satisfied: certifi==2024.2.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (2024.2.2)\n",
      "Requirement already satisfied: chardet==5.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (3.3.2)\n",
      "Requirement already satisfied: click==8.1.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (8.1.7)\n",
      "Requirement already satisfied: dataclasses-json==0.6.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (0.6.4)\n",
      "Requirement already satisfied: dataclasses-json-speakeasy==0.5.11 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (0.5.11)\n",
      "Requirement already satisfied: emoji==2.10.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (2.10.1)\n",
      "Requirement already satisfied: filetype==1.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: idna==3.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (3.6)\n",
      "Requirement already satisfied: joblib==1.3.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (1.3.2)\n",
      "Requirement already satisfied: jsonpath-python==1.0.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (1.0.6)\n",
      "Requirement already satisfied: langdetect==1.0.9 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: lxml==5.1.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (5.1.0)\n",
      "Requirement already satisfied: marshmallow==3.20.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (3.20.2)\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (1.0.0)\n",
      "INFO: pip is looking at multiple versions of unstructured to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.15.12-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: python-magic in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: tabulate in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: python-iso639 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (2024.2.7)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (3.6.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (4.9.0)\n",
      "Requirement already satisfied: unstructured-client in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (0.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (4.66.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured) (6.0.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai) (4.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai) (2.9.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Collecting typing-extensions (from unstructured)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (0.2.38)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (0.1.121)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (8.5.0)\n",
      "INFO: pip is looking at multiple versions of unstructured[all-docs] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: pikepdf in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (8.11.0)\n",
      "Requirement already satisfied: pypandoc in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (1.12)\n",
      "Requirement already satisfied: xlrd in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (2.0.1)\n",
      "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (0.3.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (3.2.1)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (1.17.0)\n",
      "Collecting python-docx>=1.1.2 (from unstructured[all-docs])\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pi-heif (from unstructured[all-docs])\n",
      "  Downloading pi_heif-0.18.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: effdet in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (0.4.1)\n",
      "Requirement already satisfied: markdown in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (3.5.2)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (3.1.2)\n",
      "Collecting unstructured-inference==0.7.36 (from unstructured[all-docs])\n",
      "  Downloading unstructured_inference-0.7.36-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: onnx in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (1.15.0)\n",
      "Collecting google-cloud-vision (from unstructured[all-docs])\n",
      "  Downloading google_cloud_vision-3.7.4-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting python-pptx>=1.0.1 (from unstructured[all-docs])\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (20221105)\n",
      "Requirement already satisfied: pandas in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (2.2.0)\n",
      "Requirement already satisfied: layoutparser in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (0.3.4)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (0.0.9)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (0.23.5)\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (4.8.0.76)\n",
      "Collecting onnxruntime>=1.17.0 (from unstructured-inference==0.7.36->unstructured[all-docs])\n",
      "  Downloading onnxruntime-1.19.2-cp311-cp311-win_amd64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (3.7.2)\n",
      "Requirement already satisfied: torch in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (2.2.0)\n",
      "Requirement already satisfied: timm in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (0.9.12)\n",
      "Requirement already satisfied: transformers>=4.25.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (4.44.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (2024.2.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (1.6.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (10.2.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (0.9.0)\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index) (0.0.17)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from beautifulsoup4==4.12.3->unstructured) (2.5)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index) (0.5.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.3)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from python-pptx>=1.0.1->unstructured[all-docs]) (3.1.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests->unstructured) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from tqdm->unstructured) (0.4.6)\n",
      "Requirement already satisfied: torchvision in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from effdet->unstructured[all-docs]) (0.17.0)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from effdet->unstructured[all-docs]) (2.0.7)\n",
      "Requirement already satisfied: omegaconf>=2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from effdet->unstructured[all-docs]) (2.3.0)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs])\n",
      "  Downloading google_api_core-2.20.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-cloud-vision->unstructured[all-docs]) (2.34.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-vision->unstructured[all-docs])\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-cloud-vision->unstructured[all-docs]) (4.23.4)\n",
      "Requirement already satisfied: six in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langdetect==1.0.9->unstructured) (1.16.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openpyxl->unstructured[all-docs]) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pandas->unstructured[all-docs]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pandas->unstructured[all-docs]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pandas->unstructured[all-docs]) (2024.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdfminer.six->unstructured[all-docs]) (42.0.2)\n",
      "Requirement already satisfied: olefile in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.65.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.66.1)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs])\n",
      "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (4.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (3.0.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from omegaconf>=2.0->effdet->unstructured[all-docs]) (4.9.3)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (23.5.26)\n",
      "Requirement already satisfied: sympy in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (1.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]) (1.4.5)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[all-docs]) (3.0.9)\n",
      "Requirement already satisfied: safetensors in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from timm->unstructured-inference==0.7.36->unstructured[all-docs]) (0.4.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from torch->unstructured-inference==0.7.36->unstructured[all-docs]) (3.13.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from torch->unstructured-inference==0.7.36->unstructured[all-docs]) (3.1.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference==0.7.36->unstructured[all-docs]) (0.19.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (1.10.1)\n",
      "Requirement already satisfied: iopath in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (0.1.10)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (0.10.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (2.21)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-vision->unstructured[all-docs])\n",
      "  Downloading protobuf-5.28.2-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.6.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (10.0)\n",
      "Requirement already satisfied: portalocker in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from iopath->layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from jinja2->torch->unstructured-inference==0.7.36->unstructured[all-docs]) (2.1.5)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdfplumber->layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (4.27.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (3.5.2)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from portalocker->iopath->layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (306)\n",
      "Downloading unstructured-0.15.12-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.1 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading unstructured_inference-0.7.36-py3-none-any.whl (56 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.8/1.5 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading google_cloud_vision-3.7.4-py2.py3-none-any.whl (467 kB)\n",
      "Downloading pi_heif-0.18.0-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.3/1.7 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading google_api_core-2.20.0-py3-none-any.whl (142 kB)\n",
      "Downloading onnxruntime-1.19.2-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.1 MB 4.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.0/11.1 MB 3.1 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 3.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.4/11.1 MB 3.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.7/11.1 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.2/11.1 MB 3.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.7/11.1 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.5/11.1 MB 3.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.0/11.1 MB 3.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 3.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.3/11.1 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.4/11.1 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.1 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.1 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.0/11.1 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.5/11.1 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 2.9 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "Downloading grpcio_status-1.66.1-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.28.2-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Installing collected packages: typing-extensions, protobuf, pi-heif, python-pptx, python-oxmsg, python-docx, proto-plus, nltk, onnxruntime, grpcio-status, google-api-core, unstructured, google-cloud-vision, unstructured-inference\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.4\n",
      "    Uninstalling protobuf-4.23.4:\n",
      "      Successfully uninstalled protobuf-4.23.4\n",
      "  Attempting uninstall: python-pptx\n",
      "    Found existing installation: python-pptx 0.6.23\n",
      "    Uninstalling python-pptx-0.6.23:\n",
      "      Successfully uninstalled python-pptx-0.6.23\n",
      "  Attempting uninstall: python-docx\n",
      "    Found existing installation: python-docx 1.1.0\n",
      "    Uninstalling python-docx-1.1.0:\n",
      "      Successfully uninstalled python-docx-1.1.0\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "  Attempting uninstall: onnxruntime\n",
      "    Found existing installation: onnxruntime 1.15.1\n",
      "    Uninstalling onnxruntime-1.15.1:\n",
      "      Successfully uninstalled onnxruntime-1.15.1\n",
      "  Attempting uninstall: unstructured\n",
      "    Found existing installation: unstructured 0.12.6\n",
      "    Uninstalling unstructured-0.12.6:\n",
      "      Successfully uninstalled unstructured-0.12.6\n",
      "  Attempting uninstall: unstructured-inference\n",
      "    Found existing installation: unstructured-inference 0.7.23\n",
      "    Uninstalling unstructured-inference-0.7.23:\n",
      "      Successfully uninstalled unstructured-inference-0.7.23\n",
      "Successfully installed google-api-core-2.20.0 google-cloud-vision-3.7.4 grpcio-status-1.66.1 nltk-3.9.1 onnxruntime-1.19.2 pi-heif-0.18.0 proto-plus-1.24.0 protobuf-5.28.2 python-docx-1.1.2 python-oxmsg-0.0.1 python-pptx-1.0.2 typing-extensions-4.12.2 unstructured-0.15.12 unstructured-inference-0.7.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-vector-stores-lancedb 0.1.7 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.10 which is incompatible.\n",
      "opentelemetry-proto 1.27.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.28.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pillow in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (10.2.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: open_clip_torch in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (2.26.1)\n",
      "Requirement already satisfied: torch in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: unstructured[all-docs] in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.15.12)\n",
      "Requirement already satisfied: chardet in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (5.2.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (0.4.27)\n",
      "Requirement already satisfied: nltk in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (3.9.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (0.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (4.12.3)\n",
      "Requirement already satisfied: emoji in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (2.10.1)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (0.6.4)\n",
      "Requirement already satisfied: python-iso639 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (2024.2.7)\n",
      "Requirement already satisfied: langdetect in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (1.0.9)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (3.6.1)\n",
      "Requirement already satisfied: backoff in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (4.12.2)\n",
      "Requirement already satisfied: unstructured-client in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (0.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (4.66.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (6.0.0)\n",
      "Requirement already satisfied: python-oxmsg in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (0.0.1)\n",
      "Requirement already satisfied: pikepdf in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (8.11.0)\n",
      "Requirement already satisfied: pypandoc in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (1.12)\n",
      "Requirement already satisfied: xlrd in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (2.0.1)\n",
      "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (0.3.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (3.2.1)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (1.17.0)\n",
      "Requirement already satisfied: python-docx>=1.1.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (1.1.2)\n",
      "Requirement already satisfied: pi-heif in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (0.18.0)\n",
      "Requirement already satisfied: effdet in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (0.4.1)\n",
      "Requirement already satisfied: pypdf in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (4.0.1)\n",
      "Requirement already satisfied: markdown in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (3.5.2)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (3.1.2)\n",
      "Requirement already satisfied: unstructured-inference==0.7.36 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (0.7.36)\n",
      "Requirement already satisfied: onnx in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (1.15.0)\n",
      "Requirement already satisfied: google-cloud-vision in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (3.7.4)\n",
      "Requirement already satisfied: python-pptx>=1.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (1.0.2)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (20221105)\n",
      "Requirement already satisfied: pandas in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[all-docs]) (2.2.0)\n",
      "Requirement already satisfied: layoutparser in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (0.3.4)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (0.0.9)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (0.23.5)\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (4.8.0.76)\n",
      "Requirement already satisfied: onnxruntime>=1.17.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (1.19.2)\n",
      "Requirement already satisfied: timm in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (0.9.12)\n",
      "Requirement already satisfied: transformers>=4.25.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.36->unstructured[all-docs]) (4.44.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pydantic) (2.23.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: torchvision in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from open_clip_torch) (0.17.0)\n",
      "Requirement already satisfied: ftfy in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from open_clip_torch) (6.2.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from python-pptx>=1.0.1->unstructured[all-docs]) (3.1.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests->unstructured[all-docs]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests->unstructured[all-docs]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests->unstructured[all-docs]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests->unstructured[all-docs]) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from beautifulsoup4->unstructured[all-docs]) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from dataclasses-json->unstructured[all-docs]) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from dataclasses-json->unstructured[all-docs]) (0.9.0)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from effdet->unstructured[all-docs]) (2.0.7)\n",
      "Requirement already satisfied: omegaconf>=2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from effdet->unstructured[all-docs]) (2.3.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from timm->unstructured-inference==0.7.36->unstructured[all-docs]) (6.0.1)\n",
      "Requirement already satisfied: safetensors in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from timm->unstructured-inference==0.7.36->unstructured[all-docs]) (0.4.5)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from ftfy->open_clip_torch) (0.2.13)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (2.20.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-cloud-vision->unstructured[all-docs]) (2.34.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-cloud-vision->unstructured[all-docs]) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-cloud-vision->unstructured[all-docs]) (5.28.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from tqdm->unstructured[all-docs]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: click in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nltk->unstructured[all-docs]) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nltk->unstructured[all-docs]) (1.3.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openpyxl->unstructured[all-docs]) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pandas->unstructured[all-docs]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pandas->unstructured[all-docs]) (2024.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdfminer.six->unstructured[all-docs]) (42.0.2)\n",
      "Requirement already satisfied: Deprecated in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pikepdf->unstructured[all-docs]) (1.2.14)\n",
      "Requirement already satisfied: olefile in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from python-oxmsg->unstructured[all-docs]) (0.47)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: dataclasses-json-speakeasy>=0.5.11 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-client->unstructured[all-docs]) (0.5.11)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-client->unstructured[all-docs]) (1.0.6)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-client->unstructured[all-docs]) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.65.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.66.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.66.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (4.9)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from omegaconf>=2.0->effdet->unstructured[all-docs]) (4.9.3)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (23.5.26)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference==0.7.36->unstructured[all-docs]) (0.19.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (1.10.1)\n",
      "Requirement already satisfied: iopath in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (0.1.10)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (0.10.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (2.21)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.6.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (10.0)\n",
      "Requirement already satisfied: portalocker in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from iopath->layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (2.8.2)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdfplumber->layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (4.27.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[all-docs]) (3.5.2)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from portalocker->iopath->layoutparser->unstructured-inference==0.7.36->unstructured[all-docs]) (306)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: boto3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (1.35.20)\n",
      "Requirement already satisfied: pillow_heif in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.15.0)\n",
      "Requirement already satisfied: lancedb in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.1.20)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.20 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from boto3) (1.35.20)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: pillow>=9.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pillow_heif) (10.2.0)\n",
      "Requirement already satisfied: deprecation in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb) (2.1.0)\n",
      "Requirement already satisfied: pylance==0.17.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb) (0.17.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb) (2.31.0)\n",
      "Requirement already satisfied: retry>=0.9.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb) (0.9.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb) (4.66.2)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb) (2.9.1)\n",
      "Requirement already satisfied: attrs>=21.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb) (24.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb) (23.2)\n",
      "Requirement already satisfied: cachetools in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb) (5.5.0)\n",
      "Requirement already satisfied: overrides>=0.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb) (7.7.0)\n",
      "Requirement already satisfied: pyarrow>=12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pylance==0.17.0->lancedb) (17.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pylance==0.17.0->lancedb) (1.26.4)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain_openai) (0.2.38)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain_openai) (1.46.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from botocore<1.36.0,>=1.35.20->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from botocore<1.36.0,>=1.35.20->boto3) (1.26.18)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (0.1.121)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pydantic>=1.10->lancedb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pydantic>=1.10->lancedb) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests>=2.31.0->lancedb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests>=2.31.0->lancedb) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests>=2.31.0->lancedb) (2024.2.2)\n",
      "Requirement already satisfied: decorator>=3.4.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from retry>=0.9.2->lancedb) (5.1.1)\n",
      "Requirement already satisfied: py<2.0.0,>=1.4.26 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from retry>=0.9.2->lancedb) (1.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from tqdm>=4.27.0->lancedb) (0.4.6)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_openai) (3.10.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.20->boto3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting unstructured-inference==0.7.23\n",
      "  Downloading unstructured_inference-0.7.23-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting unstructured==0.12.6\n",
      "  Downloading unstructured-0.12.6-py3-none-any.whl.metadata (83 kB)\n",
      "Requirement already satisfied: layoutparser[layoutmodels,tesseract] in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.23) (0.3.4)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.23) (0.0.9)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.23) (0.23.5)\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.23) (4.8.0.76)\n",
      "Requirement already satisfied: onnx in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.23) (1.15.0)\n",
      "Collecting onnxruntime<1.16 (from unstructured-inference==0.7.23)\n",
      "  Downloading onnxruntime-1.15.1-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: transformers>=4.25.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.23) (4.44.2)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured-inference==0.7.23) (3.6.1)\n",
      "Requirement already satisfied: backoff==2.2.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (4.12.3)\n",
      "Requirement already satisfied: certifi==2024.2.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (2024.2.2)\n",
      "Requirement already satisfied: chardet==5.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (3.3.2)\n",
      "Requirement already satisfied: click==8.1.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (8.1.7)\n",
      "Requirement already satisfied: dataclasses-json==0.6.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (0.6.4)\n",
      "Requirement already satisfied: dataclasses-json-speakeasy==0.5.11 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (0.5.11)\n",
      "Requirement already satisfied: emoji==2.10.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (2.10.1)\n",
      "Requirement already satisfied: filetype==1.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (1.2.0)\n",
      "Requirement already satisfied: idna==3.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (3.6)\n",
      "Requirement already satisfied: joblib==1.3.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (1.3.2)\n",
      "Requirement already satisfied: jsonpath-python==1.0.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (1.0.6)\n",
      "Requirement already satisfied: langdetect==1.0.9 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (1.0.9)\n",
      "Requirement already satisfied: lxml==5.1.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (5.1.0)\n",
      "Requirement already satisfied: marshmallow==3.20.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (3.20.2)\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (1.0.0)\n",
      "Collecting nltk==3.8.1 (from unstructured==0.12.6)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (1.26.4)\n",
      "Requirement already satisfied: packaging==23.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (23.2)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (2.8.2)\n",
      "Requirement already satisfied: python-iso639==2024.2.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (2024.2.7)\n",
      "Requirement already satisfied: python-magic==0.4.27 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (0.4.27)\n",
      "Requirement already satisfied: regex==2023.12.25 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (2023.12.25)\n",
      "Requirement already satisfied: requests==2.31.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (2.31.0)\n",
      "Requirement already satisfied: six==1.16.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (1.16.0)\n",
      "Requirement already satisfied: soupsieve==2.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (2.5)\n",
      "Requirement already satisfied: tabulate==0.9.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (0.9.0)\n",
      "Requirement already satisfied: tqdm==4.66.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (4.66.2)\n",
      "Collecting typing-extensions==4.9.0 (from unstructured==0.12.6)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-inspect==0.9.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (0.9.0)\n",
      "Requirement already satisfied: unstructured-client==0.18.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (0.18.0)\n",
      "Requirement already satisfied: urllib3==1.26.18 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (1.26.18)\n",
      "Requirement already satisfied: wrapt==1.16.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured==0.12.6) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from click==8.1.7->unstructured==0.12.6) (0.4.6)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from onnxruntime<1.16->unstructured-inference==0.7.23) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from onnxruntime<1.16->unstructured-inference==0.7.23) (23.5.26)\n",
      "Requirement already satisfied: protobuf in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from onnxruntime<1.16->unstructured-inference==0.7.23) (5.28.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from onnxruntime<1.16->unstructured-inference==0.7.23) (1.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference==0.7.23) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference==0.7.23) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference==0.7.23) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference==0.7.23) (0.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from huggingface-hub->unstructured-inference==0.7.23) (2024.2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (1.10.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (2.2.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (10.2.0)\n",
      "Requirement already satisfied: iopath in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (0.1.10)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (0.10.4)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (1.17.0)\n",
      "Requirement already satisfied: torch in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (2.2.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (0.17.0)\n",
      "Requirement already satisfied: effdet in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (0.4.1)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (0.3.10)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from coloredlogs->onnxruntime<1.16->unstructured-inference==0.7.23) (10.0)\n",
      "Requirement already satisfied: timm>=0.9.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (0.9.12)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (2.0.7)\n",
      "Requirement already satisfied: omegaconf>=2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (2.3.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (3.1.3)\n",
      "Requirement already satisfied: portalocker in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pandas->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pandas->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (2024.1)\n",
      "Requirement already satisfied: pdfminer.six==20221105 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (20221105)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (4.27.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (42.0.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from sympy->onnxruntime<1.16->unstructured-inference==0.7.23) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime<1.16->unstructured-inference==0.7.23) (3.5.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (4.9.3)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (3.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (2.1.5)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from portalocker->iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (306)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (1.4.5)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (3.0.9)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.23) (2.21)\n",
      "Downloading unstructured_inference-0.7.23-py3-none-any.whl (60 kB)\n",
      "Downloading unstructured-0.12.6-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.8 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.8/1.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 4.2 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading onnxruntime-1.15.1-cp311-cp311-win_amd64.whl (6.7 MB)\n",
      "   ---------------------------------------- 0.0/6.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.7 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.1/6.7 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.1/6.7 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.9/6.7 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.7/6.7 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.8/6.7 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.6/6.7 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.7/6.7 MB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: typing-extensions, nltk, onnxruntime, unstructured, unstructured-inference\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.9.1\n",
      "    Uninstalling nltk-3.9.1:\n",
      "      Successfully uninstalled nltk-3.9.1\n",
      "  Attempting uninstall: onnxruntime\n",
      "    Found existing installation: onnxruntime 1.19.2\n",
      "    Uninstalling onnxruntime-1.19.2:\n",
      "      Successfully uninstalled onnxruntime-1.19.2\n",
      "  Attempting uninstall: unstructured\n",
      "    Found existing installation: unstructured 0.15.12\n",
      "    Uninstalling unstructured-0.15.12:\n",
      "      Successfully uninstalled unstructured-0.15.12\n",
      "  Attempting uninstall: unstructured-inference\n",
      "    Found existing installation: unstructured-inference 0.7.36\n",
      "    Uninstalling unstructured-inference-0.7.36:\n",
      "      Successfully uninstalled unstructured-inference-0.7.36\n",
      "Successfully installed nltk-3.8.1 onnxruntime-1.15.1 typing-extensions-4.9.0 unstructured-0.12.6 unstructured-inference-0.7.23\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "altair 5.4.1 requires typing-extensions>=4.10.0; python_version < \"3.13\", but you have typing-extensions 4.9.0 which is incompatible.\n",
      "llama-index 0.11.10 requires nltk>3.8.1, but you have nltk 3.8.1 which is incompatible.\n",
      "llama-index-core 0.11.10 requires nltk>3.8.1, but you have nltk 3.8.1 which is incompatible.\n",
      "llama-index-vector-stores-lancedb 0.1.7 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.10 which is incompatible.\n",
      "openai 1.46.1 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.9.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.comNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "accelerate 0.34.2 requires huggingface-hub>=0.21.0, but you have huggingface-hub 0.20.3 which is incompatible.\n",
      "accelerate 0.34.2 requires safetensors>=0.4.3, but you have safetensors 0.3.2 which is incompatible.\n",
      "grpcio-status 1.66.1 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.23.4 which is incompatible.\n",
      "llama-index-llms-huggingface 0.3.4 requires huggingface-hub<0.24.0,>=0.23.0, but you have huggingface-hub 0.20.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: nltk in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (20221105)\n",
      "Requirement already satisfied: unstructured[pdf] in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.12.6)\n",
      "Requirement already satisfied: click in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdf2image) (10.2.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdfminer.six) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdfminer.six) (42.0.2)\n",
      "Requirement already satisfied: backoff==2.2.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (4.12.3)\n",
      "Requirement already satisfied: certifi==2024.2.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2024.2.2)\n",
      "Requirement already satisfied: chardet==5.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (5.2.0)\n",
      "Requirement already satisfied: dataclasses-json==0.6.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.6.4)\n",
      "Requirement already satisfied: dataclasses-json-speakeasy==0.5.11 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.5.11)\n",
      "Requirement already satisfied: emoji==2.10.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2.10.1)\n",
      "Requirement already satisfied: filetype==1.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.2.0)\n",
      "Requirement already satisfied: idna==3.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (3.6)\n",
      "Requirement already satisfied: jsonpath-python==1.0.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.0.6)\n",
      "Requirement already satisfied: langdetect==1.0.9 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.0.9)\n",
      "Requirement already satisfied: lxml==5.1.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (5.1.0)\n",
      "Requirement already satisfied: marshmallow==3.20.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (3.20.2)\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.0.0)\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.26.4)\n",
      "Requirement already satisfied: packaging==23.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (23.2)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2.8.2)\n",
      "Requirement already satisfied: python-iso639==2024.2.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2024.2.7)\n",
      "Requirement already satisfied: python-magic==0.4.27 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.4.27)\n",
      "Requirement already satisfied: rapidfuzz==3.6.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (3.6.1)\n",
      "Requirement already satisfied: requests==2.31.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2.31.0)\n",
      "Requirement already satisfied: six==1.16.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.16.0)\n",
      "Requirement already satisfied: soupsieve==2.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2.5)\n",
      "Requirement already satisfied: tabulate==0.9.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions==4.9.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect==0.9.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.9.0)\n",
      "Requirement already satisfied: unstructured-client==0.18.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.18.0)\n",
      "Requirement already satisfied: urllib3==1.26.18 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.26.18)\n",
      "Requirement already satisfied: wrapt==1.16.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.16.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (4.9.3)\n",
      "Requirement already satisfied: cffi==1.16.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.16.0)\n",
      "Requirement already satisfied: coloredlogs==15.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (15.0.1)\n",
      "Requirement already satisfied: contourpy==1.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.2.0)\n",
      "Requirement already satisfied: cycler==0.12.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.12.1)\n",
      "Requirement already satisfied: deprecated==1.2.14 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.2.14)\n",
      "Requirement already satisfied: effdet==0.4.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.4.1)\n",
      "Requirement already satisfied: filelock==3.13.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (3.13.1)\n",
      "Requirement already satisfied: flatbuffers==23.5.26 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (23.5.26)\n",
      "Requirement already satisfied: fonttools==4.49.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (4.49.0)\n",
      "Requirement already satisfied: fsspec==2024.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2024.2.0)\n",
      "Collecting huggingface-hub==0.20.3 (from unstructured[pdf])\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: humanfriendly==10.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (10.0)\n",
      "Requirement already satisfied: importlib-resources==6.1.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (6.1.1)\n",
      "Requirement already satisfied: iopath==0.1.10 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.1.10)\n",
      "Requirement already satisfied: jinja2==3.1.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (3.1.3)\n",
      "Requirement already satisfied: kiwisolver==1.4.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.4.5)\n",
      "Requirement already satisfied: layoutparser==0.3.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from layoutparser[layoutmodels,tesseract]==0.3.4; extra == \"pdf\"->unstructured[pdf]) (0.3.4)\n",
      "Requirement already satisfied: markupsafe==2.1.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2.1.5)\n",
      "Requirement already satisfied: matplotlib==3.7.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (3.7.2)\n",
      "Requirement already satisfied: mpmath==1.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.3.0)\n",
      "Requirement already satisfied: networkx==3.2.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (3.2.1)\n",
      "Requirement already satisfied: omegaconf==2.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2.3.0)\n",
      "Requirement already satisfied: onnx==1.15.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.15.0)\n",
      "Requirement already satisfied: onnxruntime==1.15.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.15.1)\n",
      "Requirement already satisfied: opencv-python==4.8.0.76 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (4.8.0.76)\n",
      "Requirement already satisfied: pandas==2.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2.2.0)\n",
      "Requirement already satisfied: pdfplumber==0.10.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.10.4)\n",
      "Requirement already satisfied: pikepdf==8.11.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (8.11.0)\n",
      "Requirement already satisfied: pillow-heif==0.15.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.15.0)\n",
      "Requirement already satisfied: portalocker==2.8.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2.8.2)\n",
      "Collecting protobuf==4.23.4 (from unstructured[pdf])\n",
      "  Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: pycocotools==2.0.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2.0.7)\n",
      "Requirement already satisfied: pycparser==2.21 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2.21)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (3.0.9)\n",
      "Requirement already satisfied: pypdf==4.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (4.0.1)\n",
      "Requirement already satisfied: pypdfium2==4.27.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (4.27.0)\n",
      "Requirement already satisfied: pytesseract==0.3.10 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.3.10)\n",
      "Requirement already satisfied: python-multipart==0.0.9 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.0.9)\n",
      "Requirement already satisfied: pytz==2024.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2024.1)\n",
      "Requirement already satisfied: pyyaml==6.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (6.0.1)\n",
      "Collecting safetensors==0.3.2 (from unstructured[pdf])\n",
      "  Downloading safetensors-0.3.2-cp311-cp311-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: scipy==1.10.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.10.1)\n",
      "Requirement already satisfied: sympy==1.12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (1.12)\n",
      "Requirement already satisfied: timm==0.9.12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.9.12)\n",
      "Collecting tokenizers==0.15.2 (from unstructured[pdf])\n",
      "  Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: torch==2.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2.2.0)\n",
      "Requirement already satisfied: torchvision==0.17.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.17.0)\n",
      "Collecting transformers==4.37.1 (from unstructured[pdf])\n",
      "  Downloading transformers-4.37.1-py3-none-any.whl.metadata (129 kB)\n",
      "Requirement already satisfied: tzdata==2024.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (2024.1)\n",
      "Requirement already satisfied: unstructured-inference==0.7.23 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.7.23)\n",
      "Requirement already satisfied: unstructured-pytesseract==0.3.12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (0.3.12)\n",
      "Requirement already satisfied: zipp==3.17.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from unstructured[pdf]) (3.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from humanfriendly==10.0->unstructured[pdf]) (3.5.2)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from portalocker==2.8.2->unstructured[pdf]) (306)\n",
      "Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl (422 kB)\n",
      "Downloading safetensors-0.3.2-cp311-cp311-win_amd64.whl (266 kB)\n",
      "Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.2 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading transformers-4.37.1-py3-none-any.whl (8.4 MB)\n",
      "   ---------------------------------------- 0.0/8.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/8.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.6/8.4 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.6/8.4 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.7/8.4 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 4.7/8.4 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.0/8.4 MB 4.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.1/8.4 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.1/8.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.4/8.4 MB 4.9 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, protobuf, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.4.5\n",
      "    Uninstalling safetensors-0.4.5:\n",
      "      Successfully uninstalled safetensors-0.4.5\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.28.2\n",
      "    Uninstalling protobuf-5.28.2:\n",
      "      Successfully uninstalled protobuf-5.28.2\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.23.5\n",
      "    Uninstalling huggingface-hub-0.23.5:\n",
      "      Successfully uninstalled huggingface-hub-0.23.5\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.44.2\n",
      "    Uninstalling transformers-4.44.2:\n",
      "      Successfully uninstalled transformers-4.44.2\n",
      "Successfully installed huggingface-hub-0.20.3 protobuf-4.23.4 safetensors-0.3.2 tokenizers-0.15.2 transformers-4.37.1\n",
      "Note: you may need to restart the kernel to use updated packages.Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement poppler (from versions: none)\n",
      "ERROR: No matching distribution found for poppler\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-ollama 0.1.1 requires langchain-core<0.3.0,>=0.2.20, but you have langchain-core 0.3.2 which is incompatible.\n",
      "langchain-openai 0.1.20 requires langchain-core<0.3.0,>=0.2.26, but you have langchain-core 0.3.2 which is incompatible.\n",
      "llama-index-core 0.11.10 requires nltk>3.8.1, but you have nltk 3.8.1 which is incompatible.\n",
      "llama-index-llms-huggingface 0.3.4 requires huggingface-hub<0.24.0,>=0.23.0, but you have huggingface-hub 0.20.3 which is incompatible.\n",
      "llama-index-vector-stores-lancedb 0.1.7 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.10 which is incompatible.\n",
      "unstructured 0.12.6 requires typing-extensions==4.9.0, but you have typing-extensions 4.12.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: langchain in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.2.11)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: openai in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (1.46.1)\n",
      "Requirement already satisfied: langchain-chroma in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.1.2)\n",
      "Collecting langchain-chroma\n",
      "  Downloading langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting langchain-experimental\n",
      "  Downloading langchain_experimental-0.3.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (3.10.5)\n",
      "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_core-0.3.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (0.1.121)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (2.9.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai) (4.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai) (4.66.2)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain-chroma)\n",
      "  Downloading chromadb-0.5.7-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: fastapi<1,>=0.95.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain-chroma) (0.112.4)\n",
      "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain-experimental)\n",
      "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.6)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.30.6)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.6.6)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.15.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.15.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.1.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.66.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.12.5)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (30.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.7)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.8.1)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.38.5)\n",
      "Requirement already satisfied: certifi in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.6.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental)\n",
      "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.34.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (23.5.26)\n",
      "Requirement already satisfied: protobuf in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.23.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.48b0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (65.5.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.20.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.20.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2024.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.5.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
      "Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\n",
      "Downloading langchain_experimental-0.3.0-py3-none-any.whl (206 kB)\n",
      "Downloading chromadb-0.5.7-py3-none-any.whl (599 kB)\n",
      "   ---------------------------------------- 0.0/599.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 599.2/599.2 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.2-py3-none-any.whl (399 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: typing-extensions, pydantic-settings, langchain-core, langchain-text-splitters, chromadb, langchain-chroma, langchain, langchain-community, langchain-experimental\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.38\n",
      "    Uninstalling langchain-core-0.2.38:\n",
      "      Successfully uninstalled langchain-core-0.2.38\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.2.4\n",
      "    Uninstalling langchain-text-splitters-0.2.4:\n",
      "      Successfully uninstalled langchain-text-splitters-0.2.4\n",
      "  Attempting uninstall: chromadb\n",
      "    Found existing installation: chromadb 0.5.5\n",
      "    Uninstalling chromadb-0.5.5:\n",
      "      Successfully uninstalled chromadb-0.5.5\n",
      "  Attempting uninstall: langchain-chroma\n",
      "    Found existing installation: langchain-chroma 0.1.2\n",
      "    Uninstalling langchain-chroma-0.1.2:\n",
      "      Successfully uninstalled langchain-chroma-0.1.2\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.2.11\n",
      "    Uninstalling langchain-0.2.11:\n",
      "      Successfully uninstalled langchain-0.2.11\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.2.10\n",
      "    Uninstalling langchain-community-0.2.10:\n",
      "      Successfully uninstalled langchain-community-0.2.10\n",
      "Successfully installed chromadb-0.5.7 langchain-0.3.0 langchain-chroma-0.1.4 langchain-community-0.3.0 langchain-core-0.3.2 langchain-experimental-0.3.0 langchain-text-splitters-0.3.0 pydantic-settings-2.5.2 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data/...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install llama-index unstructured openai tiktoken langchain pypdf python-dotenv unstructured[all-docs]\n",
    "%pip install \"unstructured[all-docs]\" pillow pydantic lxml pillow matplotlib tiktoken open_clip_torch torch\n",
    "%pip install boto3 pillow_heif lancedb langchain_openai\n",
    "%pip install unstructured-inference==0.7.23 unstructured==0.12.6\n",
    "%pip install nltk pdf2image pdfminer.six unstructured[pdf]\n",
    "\n",
    "# Install system packages with apt-get\n",
    "%pip install  poppler poppler-utils tesseract-ocr\n",
    "\n",
    "# Upgrade LangChain for multi-modal capabilities\n",
    "%pip install -U langchain openai langchain-chroma langchain-experimental\n",
    "\n",
    "# Set up NLTK and specify the data directory explicitly\n",
    "import nltk\n",
    "import ssl\n",
    "import os\n",
    "\n",
    "# Configure SSL\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# Manually create the NLTK data folder if it doesn't exist\n",
    "nltk_data_dir = '/root/nltk_data/'\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "\n",
    "# Set the NLTK data path\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Download the 'punkt' tokenizer data\n",
    "nltk.download('punkt', download_dir=nltk_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: llama-index in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.11.10)\n",
      "Requirement already satisfied: llama-index-vector-stores-lancedb in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.1.7)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.3.3)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.10 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.11.10)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.2.5)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.9.48.post3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.2.9)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.2.1)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.2.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index) (0.3.0)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: lancedb>=0.8.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-vector-stores-lancedb) (0.13.0)\n",
      "INFO: pip is looking at multiple versions of llama-index-vector-stores-lancedb to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-index-vector-stores-lancedb\n",
      "  Downloading llama_index_vector_stores_lancedb-0.2.3-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting lancedb<0.13.0,>=0.8.0 (from llama-index-vector-stores-lancedb)\n",
      "  Downloading lancedb-0.12.0-cp38-abi3-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: tantivy in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-vector-stores-lancedb) (0.22.0)\n",
      "Requirement already satisfied: deprecation in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (2.1.0)\n",
      "Collecting pylance==0.16.0 (from lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb)\n",
      "  Downloading pylance-0.16.0-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting ratelimiter~=1.0 (from lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb)\n",
      "  Downloading ratelimiter-1.2.0.post0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (2.31.0)\n",
      "Requirement already satisfied: retry>=0.9.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (0.9.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (4.66.2)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (2.9.1)\n",
      "Requirement already satisfied: attrs>=21.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (24.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (23.2)\n",
      "Requirement already satisfied: cachetools in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (5.5.0)\n",
      "Requirement already satisfied: overrides>=0.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (7.7.0)\n",
      "Requirement already satisfied: pyarrow>=12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pylance==0.16.0->lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (17.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pylance==0.16.0->lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.14.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-agent-openai<0.4.0,>=0.3.1->llama-index) (1.46.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.10->llama-index) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (2024.2.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (10.2.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index) (1.16.0)\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index) (0.0.17)\n",
      "Requirement already satisfied: pandas in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.0.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index) (0.5.6)\n",
      "Requirement already satisfied: click in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nltk>3.8.1->llama-index) (2023.12.25)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.10->llama-index) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.10->llama-index) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.10->llama-index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.10->llama-index) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.10->llama-index) (1.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (2.5)\n",
      "Requirement already satisfied: anyio in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama-index) (4.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama-index) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama-index) (3.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.10->llama-index) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.1->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.1->llama-index) (0.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pydantic>=1.10->lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pydantic>=1.10->lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests>=2.31.0->lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests>=2.31.0->lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (1.26.18)\n",
      "Requirement already satisfied: decorator>=3.4.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from retry>=0.9.2->lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (5.1.1)\n",
      "Requirement already satisfied: py<2.0.0,>=1.4.26 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from retry>=0.9.2->lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (1.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.10->llama-index) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from tqdm>=4.27.0->lancedb<0.13.0,>=0.8.0->llama-index-vector-stores-lancedb) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.10->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.10->llama-index) (3.20.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
      "Downloading llama_index_vector_stores_lancedb-0.2.3-py3-none-any.whl (6.8 kB)\n",
      "Downloading lancedb-0.12.0-cp38-abi3-win_amd64.whl (22.9 MB)\n",
      "   ---------------------------------------- 0.0/22.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/22.9 MB 5.6 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.8/22.9 MB 5.6 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.4/22.9 MB 4.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.1/22.9 MB 4.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.7/22.9 MB 4.0 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 4.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.2/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/22.9 MB 3.9 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 5.8/22.9 MB 981.5 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 6.3/22.9 MB 1.0 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 7.1/22.9 MB 1.1 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 7.9/22.9 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 9.2/22.9 MB 1.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 10.0/22.9 MB 1.4 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 11.3/22.9 MB 1.6 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 12.3/22.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 13.4/22.9 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 13.9/22.9 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 13.9/22.9 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 14.2/22.9 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 14.7/22.9 MB 1.8 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 15.2/22.9 MB 1.8 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 16.0/22.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 16.5/22.9 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 17.3/22.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 18.1/22.9 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 18.6/22.9 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 19.4/22.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 20.2/22.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 21.0/22.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 21.8/22.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  22.5/22.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 22.9/22.9 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading pylance-0.16.0-cp39-abi3-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/26.4 MB 5.6 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.3/26.4 MB 3.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.1/26.4 MB 3.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 2.6/26.4 MB 3.5 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.4/26.4 MB 3.4 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.4/26.4 MB 3.4 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 2.8 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 3.9/26.4 MB 2.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 4.2/26.4 MB 2.3 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 4.5/26.4 MB 2.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 4.7/26.4 MB 2.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 5.2/26.4 MB 2.1 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 5.5/26.4 MB 2.1 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 5.8/26.4 MB 2.0 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 6.3/26.4 MB 2.0 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 6.8/26.4 MB 2.1 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 7.3/26.4 MB 2.1 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 7.9/26.4 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 8.4/26.4 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.9/26.4 MB 2.2 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 9.4/26.4 MB 2.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 10.2/26.4 MB 2.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.7/26.4 MB 2.2 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 11.3/26.4 MB 2.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 12.1/26.4 MB 2.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 12.8/26.4 MB 2.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 13.4/26.4 MB 2.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 13.6/26.4 MB 2.4 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 14.2/26.4 MB 2.4 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 14.7/26.4 MB 2.4 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 15.5/26.4 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 16.0/26.4 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 16.5/26.4 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 17.0/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.6/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 18.4/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 18.9/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 19.4/26.4 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 19.9/26.4 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 20.7/26.4 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 21.2/26.4 MB 2.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 21.8/26.4 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.5/26.4 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 23.1/26.4 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 23.6/26.4 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 24.4/26.4 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.2/26.4 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.7/26.4 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
      "Installing collected packages: ratelimiter, pylance, nltk, lancedb, llama-index-vector-stores-lancedb\n",
      "  Attempting uninstall: pylance\n",
      "    Found existing installation: pylance 0.17.0\n",
      "    Uninstalling pylance-0.17.0:\n",
      "      Successfully uninstalled pylance-0.17.0\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "  Attempting uninstall: lancedb\n",
      "    Found existing installation: lancedb 0.13.0\n",
      "    Uninstalling lancedb-0.13.0:\n",
      "      Successfully uninstalled lancedb-0.13.0\n",
      "  Attempting uninstall: llama-index-vector-stores-lancedb\n",
      "    Found existing installation: llama-index-vector-stores-lancedb 0.1.7\n",
      "    Uninstalling llama-index-vector-stores-lancedb-0.1.7:\n",
      "      Successfully uninstalled llama-index-vector-stores-lancedb-0.1.7\n",
      "Successfully installed lancedb-0.12.0 llama-index-vector-stores-lancedb-0.2.3 nltk-3.9.1 pylance-0.16.0 ratelimiter-1.2.0.post0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-llms-huggingface 0.3.4 requires huggingface-hub<0.24.0,>=0.23.0, but you have huggingface-hub 0.20.3 which is incompatible.\n",
      "unstructured 0.12.6 requires nltk==3.8.1, but you have nltk 3.9.1 which is incompatible.\n",
      "unstructured 0.12.6 requires typing-extensions==4.9.0, but you have typing-extensions 4.12.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index llama-index-vector-stores-lancedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: fitz in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: configobj in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from fitz) (5.0.8)\n",
      "Requirement already satisfied: configparser in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from fitz) (7.1.0)\n",
      "Requirement already satisfied: httplib2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from fitz) (0.22.0)\n",
      "Requirement already satisfied: nibabel in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from fitz) (5.2.1)\n",
      "Requirement already satisfied: nipype in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from fitz) (1.8.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from fitz) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from fitz) (2.2.0)\n",
      "Requirement already satisfied: pyxnat in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from fitz) (1.6.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from fitz) (1.10.1)\n",
      "Requirement already satisfied: six in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from configobj->fitz) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from httplib2->fitz) (3.0.9)\n",
      "Requirement already satisfied: packaging>=17 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nibabel->fitz) (23.2)\n",
      "Requirement already satisfied: click>=6.6.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nipype->fitz) (8.1.7)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nipype->fitz) (3.2.1)\n",
      "Requirement already satisfied: prov>=1.5.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nipype->fitz) (2.0.1)\n",
      "Requirement already satisfied: pydot>=1.2.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nipype->fitz) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nipype->fitz) (2.8.2)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nipype->fitz) (3.19.3)\n",
      "Requirement already satisfied: traits!=5.0,<6.4,>=4.6 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: filelock>=3.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nipype->fitz) (3.13.1)\n",
      "Requirement already satisfied: etelemetry>=0.2.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pandas->fitz) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pandas->fitz) (2024.1)\n",
      "Requirement already satisfied: lxml>=4.3 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pyxnat->fitz) (5.1.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pyxnat->fitz) (2.31.0)\n",
      "Requirement already satisfied: pathlib>=1.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from click>=6.6.0->nipype->fitz) (0.4.6)\n",
      "Requirement already satisfied: ci-info>=0.2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from etelemetry>=0.2.0->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests>=2.20->pyxnat->fitz) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests>=2.20->pyxnat->fitz) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests>=2.20->pyxnat->fitz) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from requests>=2.20->pyxnat->fitz) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pymupdf in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (1.24.10)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.10 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pymupdf) (1.24.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting poppler-utils\n",
      "  Downloading poppler_utils-0.1.0-py3-none-any.whl.metadata (883 bytes)\n",
      "Collecting tesseract-ocr\n",
      "  Downloading tesseract-ocr-0.0.1.tar.gz (33 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: Click>=7.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from poppler-utils) (8.1.7)\n",
      "Collecting cython (from tesseract-ocr)\n",
      "  Downloading Cython-3.0.11-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from Click>=7.0->poppler-utils) (0.4.6)\n",
      "Downloading poppler_utils-0.1.0-py3-none-any.whl (9.2 kB)\n",
      "Downloading Cython-3.0.11-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.6/2.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 4.9 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: tesseract-ocr\n",
      "  Building wheel for tesseract-ocr (pyproject.toml): started\n",
      "  Building wheel for tesseract-ocr (pyproject.toml): finished with status 'error'\n",
      "Failed to build tesseract-ocr\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "   Building wheel for tesseract-ocr (pyproject.toml) did not run successfully.\n",
      "   exit code: 1\n",
      "  > [29 lines of output]\n",
      "      C:\\Users\\rohit\\AppData\\Local\\Temp\\pip-build-env-wymzfma5\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:261: UserWarning: Unknown distribution option: 'tests_require'\n",
      "        warnings.warn(msg)\n",
      "      C:\\Users\\rohit\\AppData\\Local\\Temp\\pip-build-env-wymzfma5\\overlay\\Lib\\site-packages\\setuptools\\dist.py:452: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Usage of dash-separated 'description-file' will not be supported in future\n",
      "              versions. Please use the underscore name 'description_file' instead.\n",
      "      \n",
      "              By 2024-Sep-26, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        opt = self.warn_dash_deprecation(opt, section)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      file tesseract_ocr.py (for module tesseract_ocr) not found\n",
      "      file tesseract_ocr.py (for module tesseract_ocr) not found\n",
      "      running build_ext\n",
      "      building 'tesseract_ocr' extension\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\n",
      "      \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.40.33807\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -Ic:\\Users\\rohit\\Sarvam-ai\\sarv\\include -IC:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python311\\include -IC:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python311\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.40.33807\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.40.33807\\ATLMFC\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt\" -IC:\\Users\\rohit\\vcpkg\\installed\\x64-windows\\include /EHsc /Tptesseract_ocr.cpp /Fobuild\\temp.win-amd64-cpython-311\\Release\\tesseract_ocr.obj\n",
      "      tesseract_ocr.cpp\n",
      "      tesseract_ocr.cpp(265): fatal error C1083: Cannot open include file: 'tesseract/baseapi.h': No such file or directory\n",
      "      error: command 'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.40.33807\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tesseract-ocr\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tesseract-ocr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.comNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (20221105)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdfminer.six) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdfminer.six) (42.0.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdf2image) (10.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n"
     ]
    }
   ],
   "source": [
    "%pip install fitz\n",
    "%pip install pymupdf\n",
    "# Install Poppler and Tesseract\n",
    "%pip install poppler-utils tesseract-ocr\n",
    "\n",
    "# Install PDF processing libraries\n",
    "%pip install pdfminer.six pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting poppler-utils\n",
      "  Downloading poppler_utils-0.1.0-py3-none-any.whl.metadata (883 bytes)\n",
      "Collecting tesseract-ocr\n",
      "  Downloading tesseract-ocr-0.0.1.tar.gz (33 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: Click>=7.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from poppler-utils) (8.1.7)\n",
      "Collecting cython (from tesseract-ocr)\n",
      "  Downloading Cython-3.0.11-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from Click>=7.0->poppler-utils) (0.4.6)\n",
      "Downloading poppler_utils-0.1.0-py3-none-any.whl (9.2 kB)\n",
      "Downloading Cython-3.0.11-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.8 MB 1.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 0.8/2.8 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.3/2.8 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.8/2.8 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.4/2.8 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 2.0 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: tesseract-ocr\n",
      "  Building wheel for tesseract-ocr (pyproject.toml): started\n",
      "  Building wheel for tesseract-ocr (pyproject.toml): finished with status 'error'\n",
      "Failed to build tesseract-ocr\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "   Building wheel for tesseract-ocr (pyproject.toml) did not run successfully.\n",
      "   exit code: 1\n",
      "  > [29 lines of output]\n",
      "      C:\\Users\\rohit\\AppData\\Local\\Temp\\pip-build-env-iup35qhc\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:261: UserWarning: Unknown distribution option: 'tests_require'\n",
      "        warnings.warn(msg)\n",
      "      C:\\Users\\rohit\\AppData\\Local\\Temp\\pip-build-env-iup35qhc\\overlay\\Lib\\site-packages\\setuptools\\dist.py:452: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Usage of dash-separated 'description-file' will not be supported in future\n",
      "              versions. Please use the underscore name 'description_file' instead.\n",
      "      \n",
      "              By 2024-Sep-26, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        opt = self.warn_dash_deprecation(opt, section)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      file tesseract_ocr.py (for module tesseract_ocr) not found\n",
      "      file tesseract_ocr.py (for module tesseract_ocr) not found\n",
      "      running build_ext\n",
      "      building 'tesseract_ocr' extension\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\n",
      "      \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.40.33807\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -Ic:\\Users\\rohit\\Sarvam-ai\\sarv\\include -IC:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python311\\include -IC:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python311\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.40.33807\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.40.33807\\ATLMFC\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt\" -IC:\\Users\\rohit\\vcpkg\\installed\\x64-windows\\include /EHsc /Tptesseract_ocr.cpp /Fobuild\\temp.win-amd64-cpython-311\\Release\\tesseract_ocr.obj\n",
      "      tesseract_ocr.cpp\n",
      "      tesseract_ocr.cpp(265): fatal error C1083: Cannot open include file: 'tesseract/baseapi.h': No such file or directory\n",
      "      error: command 'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.40.33807\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tesseract-ocr\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tesseract-ocr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (20221105)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdfminer.six) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdfminer.six) (42.0.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from pdf2image) (10.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rohit\\sarvam-ai\\sarv\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install Poppler and Tesserac\n",
    "%pip install poppler-utils tesseract-ocr\n",
    "\n",
    "# Install PDF processing libraries\n",
    "%pip install pdfminer.six pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.trainer_callback because of the following error (look up to see its traceback):\ncannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (c:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1364\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\transformers\\trainer_callback.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IntervalStrategy, has_length\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_args\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\transformers\\training_args.py:70\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AcceleratorState, PartialState\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedType\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\accelerate\\__init__.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.34.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     cpu_offload,\n\u001b[0;32m     19\u001b[0m     cpu_offload_with_hook,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[0;32m     25\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\accelerate\\accelerator.py:34\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_torch_state_dict_into_shards\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (c:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\huggingface_hub\\__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocumentBuilder\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mExtractor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocumentExtractor\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mVdb_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexHandler\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\Vdb_handler.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StorageContext\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# from llama_index.llms.huggingface import HuggingFaceLLM\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbedding\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mollama\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ollama\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreact\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReActAgent\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\llama_index\\embeddings\\huggingface\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     HuggingFaceEmbedding,\n\u001b[0;32m      3\u001b[0m     HuggingFaceInferenceAPIEmbedding,\n\u001b[0;32m      4\u001b[0m     HuggingFaceInferenceAPIEmbeddings,\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuggingFaceEmbedding\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuggingFaceInferenceAPIEmbedding\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuggingFaceInferenceAPIEmbeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\llama_index\\embeddings\\huggingface\\base.py:28\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_cache_dir, infer_torch_device\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     DEFAULT_HUGGINGFACE_EMBEDDING_MODEL,\n\u001b[0;32m     23\u001b[0m     format_query,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     get_text_instruct_for_model_name,\n\u001b[0;32m     27\u001b[0m )\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     30\u001b[0m DEFAULT_HUGGINGFACE_LENGTH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[0;32m     31\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\sentence_transformers\\__init__.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceTransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fullname, get_device_name, import_from_string\n\u001b[0;32m     21\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trange\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_npu_available\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerModelCardData, generate_model_card\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimilarity_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimilarityFunction\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __MODEL_HUB_ORGANIZATION__, __version__\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\sentence_transformers\\model_card.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerCallback\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeCarbonCallback\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelcard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_markdown_table\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1354\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1352\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1354\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1355\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1366\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1367\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.trainer_callback because of the following error (look up to see its traceback):\ncannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (c:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "from Builder import DocumentBuilder\n",
    "from Extractor import DocumentExtractor\n",
    "from Vdb_handler import IndexHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(filename, db_url=\"./.lancedb\"):\n",
    "\n",
    "    extractor = DocumentExtractor(filename=filename)\n",
    "    df_metadata = extractor.extract_metadata()\n",
    "\n",
    "    if df_metadata.empty:\n",
    "        print(f\"No valid metadata extracted from {filename}\")\n",
    "        return None\n",
    "\n",
    "    builder = DocumentBuilder(metadata=df_metadata)\n",
    "    _, df_enriched = builder.build(filename)\n",
    "    df_enriched=df_enriched.sort_values(by=\"page_number\")\n",
    "    df_enriched.to_csv(\"df_enriched.csv\")\n",
    "    index_handler = IndexHandler(metadata=df_enriched, db_url=db_url)\n",
    "    index_handler.add_documents_to_lancedb_table(df_enriched)\n",
    "\n",
    "    agent = index_handler.create_query_engine(\n",
    "        index_handler.vector_table_name\n",
    "    )\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ret\u001b[38;5;241m=\u001b[39m\u001b[43mmain\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miesc111.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "ret=main(\"iesc111.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during PDF extraction: Failed to import transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder because of the following error (look up to see its traceback):\n",
      "cannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (c:\\Users\\rohit\\Sarvam-ai\\sarv\\Lib\\site-packages\\huggingface_hub\\__init__.py)\n",
      "No valid metadata extracted from iesc111.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "from typing import List, Optional, Any\n",
    "from io import BytesIO\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lancedb\n",
    "import pyarrow as pa\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.agent.react import ReActAgent\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from sentence_transformer import SentenceTransformer\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "class DocumentExtractor:\n",
    "    def __init__(self, filename, output_dir=\"/doc/\"):\n",
    "        self.filename = filename\n",
    "        self.output_dir = output_dir\n",
    "        self.filetype = filename.split('.')[-1].lower()\n",
    "        self.meta_columns = [\"type\", \"text\", \"filename\", \"page_number\", \"coordinates\", \"text_as_html\"]\n",
    "\n",
    "    def extract_metadata(self):\n",
    "        elements = self.extract_elements()\n",
    "        if not elements:\n",
    "            return pd.DataFrame(columns=self.meta_columns)\n",
    "\n",
    "        records = self.convert_to_dict(elements=elements)\n",
    "        records_df = pd.DataFrame(records)\n",
    "\n",
    "        # Ensure required columns exist\n",
    "        for col in self.meta_columns:\n",
    "            if col not in records_df.columns:\n",
    "                records_df[col] = None\n",
    "\n",
    "        # Add metadata columns\n",
    "        metadata = [ele.metadata.to_dict() for ele in elements if hasattr(ele, 'metadata')]\n",
    "        metadata_df = pd.DataFrame(metadata)\n",
    "\n",
    "        # Concatenate records_df and metadata_df, removing duplicated columns\n",
    "        df = pd.concat([records_df, metadata_df], axis=1)\n",
    "        df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def extract_elements(self):\n",
    "        if self.filetype == 'pdf':\n",
    "            return self.extract_pdf()\n",
    "        else:\n",
    "            print(f\"Unsupported filetype: {self.filetype}\")\n",
    "            return []\n",
    "\n",
    "    def extract_pdf(self):\n",
    "        try:\n",
    "            return partition_pdf(\n",
    "                filename=self.filename,\n",
    "                strategy=\"hi_res\",\n",
    "                max_characters=2000,\n",
    "                new_after_n_chars=1500,\n",
    "                infer_table_structure=True,\n",
    "                extract_images_in_pdf=True,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error during PDF extraction: {e}\")\n",
    "            return []\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_dict(elements):\n",
    "        from unstructured.staging.base import convert_to_dict\n",
    "        return convert_to_dict(elements=elements)\n",
    "\n",
    "class DocumentBuilder:\n",
    "    def __init__(self, metadata: pd.DataFrame):\n",
    "        self.metadata = metadata\n",
    "        self.data_model = {\n",
    "            \"filetype\": \"first\",\n",
    "            \"last_modified\": \"first\",\n",
    "            \"type\": \"first\",\n",
    "            \"page_number\": \"first\",\n",
    "            \"coordinates\": \"first\",\n",
    "            \"text_as_html\": \"sum\",\n",
    "        }\n",
    "        self.client = InferenceClient(\n",
    "            \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "            token=\"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\",\n",
    "        )\n",
    "\n",
    "    def segregate_metadata(self):\n",
    "        text_df = self.metadata[(self.metadata[\"type\"] != \"Table\") & (self.metadata[\"type\"] != \"TableChunk\") & (self.metadata[\"type\"] != \"Image\")]\n",
    "        table_df = self.metadata[(self.metadata[\"type\"] == \"Table\") | (self.metadata[\"type\"] == \"TableChunk\")]\n",
    "        image_df = self.metadata[self.metadata[\"type\"] == \"Image\"]\n",
    "\n",
    "        # Drop filename before aggregation to avoid conflicts\n",
    "        filename_column = table_df[\"filename\"].copy()\n",
    "        table_df = table_df.drop(columns=[\"filename\"])\n",
    "\n",
    "        # Perform aggregation and then reattach the filename\n",
    "        table_df = table_df.groupby(filename_column).agg(self.data_model).reset_index()\n",
    "\n",
    "        return table_df, text_df, image_df\n",
    "\n",
    "    # @staticmethod\n",
    "    # def convert_pdf_page_to_image(pdf_path, page_number):\n",
    "    #     images = convert_from_path(pdf_path, first_page=page_number, last_page=page_number)\n",
    "    #     if images:\n",
    "    #         buffer = BytesIO()\n",
    "    #         images[0].save(buffer, format=\"PNG\")\n",
    "    #         return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "    #     return None\n",
    "\n",
    "    def build(self, pdf_path):\n",
    "        table_df, text_df, image_df = self.segregate_metadata()\n",
    "        \n",
    "        # Summarize tables\n",
    "        table_df = self.table_summarization(table_df=table_df)\n",
    "\n",
    "        # Summarize images\n",
    "        # image_df = self.image_summarization(image_df=image_df, pdf_path=pdf_path)\n",
    "\n",
    "        # Remove any duplicate columns\n",
    "        text_df = text_df.loc[:, ~text_df.columns.duplicated()]\n",
    "        table_df = table_df.loc[:, ~table_df.columns.duplicated()]\n",
    "        image_df = image_df.loc[:, ~image_df.columns.duplicated()]\n",
    "\n",
    "        # Concatenate dataframes\n",
    "        df = pd.concat([text_df, table_df, image_df], axis=0, ignore_index=True)\n",
    "\n",
    "        # Ensure \"label\" column exists\n",
    "        if \"label\" not in df.columns:\n",
    "            df[\"label\"] = pd.NA\n",
    "\n",
    "        return df\n",
    "\n",
    "    def table_summarization(self, table_df):\n",
    "        table_summarization_template = \"\"\"\n",
    "        Summarize the following HTML table. Try to create key-value mappings. Respond in bullet points.\n",
    "        Do not miss any information. Do not generate text in bold.\n",
    "        html_table: {text_as_html}\n",
    "        \"\"\"\n",
    "        for i, row in table_df.iterrows():\n",
    "            formatted_prompt = table_summarization_template.format(text_as_html=row[\"text_as_html\"])\n",
    "            summary = self.llama_text(message=formatted_prompt)\n",
    "            if 'text' not in table_df.columns:\n",
    "                table_df['text'] = None\n",
    "            table_df.at[i, 'text'] = summary\n",
    "        return table_df\n",
    "\n",
    "    # def image_summarization(self, image_df, pdf_path):\n",
    "    #     unique_pages = set()\n",
    "    #     rows_to_remove = []\n",
    "\n",
    "    #     for i, row in image_df.iterrows():\n",
    "    #         page_number = row.get('page_number')\n",
    "\n",
    "    #         if page_number not in unique_pages:\n",
    "    #             unique_pages.add(page_number)\n",
    "    #             base64_image = self.convert_pdf_page_to_image(pdf_path, page_number)\n",
    "    #             if base64_image:\n",
    "    #                 image_summary = self.call_openai_image(base64_image)\n",
    "    #                 image_df.at[i, 'text'] = image_summary\n",
    "    #             else:\n",
    "    #                 rows_to_remove.append(i)\n",
    "    #         else:\n",
    "    #             rows_to_remove.append(i)\n",
    "\n",
    "    #     # Remove the marked rows from the DataFrame\n",
    "    #     image_df = image_df.drop(rows_to_remove).reset_index(drop=True)\n",
    "\n",
    "    #     return image_df\n",
    "\n",
    "    def llama_text(self, message):\n",
    "        messages = self.client.chat_completion(\n",
    "            messages=[{\"role\": \"user\", \"content\": message}],\n",
    "            stream=True,\n",
    "        )\n",
    "        return messages.choices[0].delta.content\n",
    "\n",
    "    # @staticmethod\n",
    "    # def call_openai_image(base64_image):\n",
    "    #     from openai import OpenAI\n",
    "    #     client = OpenAI()\n",
    "    #     response = client.chat.completions.create(\n",
    "    #         model=\"gpt-4-vision-preview\",\n",
    "    #         messages=[\n",
    "    #             {\n",
    "    #                 \"role\": \"user\",\n",
    "    #                 \"content\": [\n",
    "    #                     {\"type\": \"text\", \"text\": \"Summarize all the images, graphs, and charts on this page. If the image is a graph or a chart, create a summary in bullet points.\"},\n",
    "    #                     {\n",
    "    #                         \"type\": \"image_url\",\n",
    "    #                         \"image_url\": {\n",
    "    #                             \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "    #                         },\n",
    "    #                     },\n",
    "    #                 ],\n",
    "    #             }\n",
    "    #         ],\n",
    "    #         max_tokens=250,\n",
    "    #     )\n",
    "    #     return response.choices[0].message.content\n",
    "\n",
    "class IndexHandler:\n",
    "    def __init__(self, metadata: pd.DataFrame, chunk_size=2000, db_url=\"./.lancedb\", \n",
    "                 vector_table_name=\"vector_index\"):\n",
    "        self.metadata = metadata\n",
    "        self.chunk_size = chunk_size\n",
    "        self.db_url = db_url\n",
    "        self.vector_table_name = vector_table_name\n",
    "        self.embeddings = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        self.db = lancedb.connect(self.db_url)\n",
    "        self.llm = Ollama(model=\"llama2\")\n",
    "\n",
    "    def add_documents_to_lancedb_table(self, df: pd.DataFrame) -> None:\n",
    "        # Ensure 'id' field exists\n",
    "        if 'id' not in df.columns:\n",
    "            df['doc_id'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "            df['id'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "\n",
    "        # Generate embeddings\n",
    "        df['text'] = df['text'].astype(str)\n",
    "        df['vector'] = df['text'].apply(lambda x: self.embeddings.get_text_embedding(x) if pd.notna(x) else [0.0] * 384)\n",
    "\n",
    "        required_fields = [\"doc_id\", \"id\", \"text\", \"coordinates\", \"filename\", \"page_number\", \"type\", \"vector\"]\n",
    "        for field in required_fields:\n",
    "            if field not in df.columns:\n",
    "                if field == \"page_number\":\n",
    "                    df[field] = 0\n",
    "                elif field == \"vector\":\n",
    "                    df[field] = [[0.0] * 384 for _ in range(len(df))]\n",
    "                else:\n",
    "                    df[field] = \"\"\n",
    "\n",
    "        # Ensure 'page_number' is of type int64\n",
    "        df['page_number'] = pd.to_numeric(df['page_number'], errors='coerce').fillna(0).astype('int64')\n",
    "\n",
    "        # Convert metadata fields to dictionaries\n",
    "        df['metadata'] = df.apply(lambda row: {\n",
    "            'coordinates': json.dumps(row['coordinates']) if isinstance(row['coordinates'], dict) else str(row['coordinates']),\n",
    "            'filename': row['filename'],\n",
    "            'page_number': int(row['page_number']),\n",
    "            'type': row['type']\n",
    "        }, axis=1)\n",
    "\n",
    "        # Select only the columns that match our Schema\n",
    "        df_to_insert = df[['doc_id', 'id', 'text', 'metadata', 'vector']]\n",
    "\n",
    "        # Define schema\n",
    "        schema_vector = pa.schema([\n",
    "            pa.field(\"doc_id\", pa.string()),\n",
    "            pa.field(\"id\", pa.string()),\n",
    "            pa.field(\"text\", pa.string()),\n",
    "            pa.field(\"vector\", pa.list_(pa.float32(), 384)),\n",
    "            pa.field(\"metadata\", pa.struct([\n",
    "                pa.field(\"coordinates\", pa.string()),\n",
    "                pa.field(\"filename\", pa.string()),\n",
    "                pa.field(\"page_number\", pa.int64()),\n",
    "                pa.field(\"type\", pa.string())\n",
    "            ]))\n",
    "        ])\n",
    "\n",
    "        # Create or open the vector table\n",
    "        try:\n",
    "            vector_table = self.db.open_table(self.vector_table_name)\n",
    "            print(f\"Opened existing table '{self.vector_table_name}'.\")\n",
    "        except Exception:\n",
    "            print(f\"Table '{self.vector_table_name}' not found. Creating new table.\")\n",
    "            vector_table = self.db.create_table(\n",
    "                self.vector_table_name,\n",
    "                data=df_to_insert,\n",
    "                schema=schema_vector\n",
    "            )\n",
    "            vector_table.create_fts_index('text')\n",
    "            print(f\"FTS index created on the 'text' field.\")\n",
    "\n",
    "        # Add data to the table\n",
    "        vector_table.add(df_to_insert)\n",
    "        print(f\"Data added to table '{self.vector_table_name}'.\")\n",
    "        df_to_insert.to_csv(\"df_to_insert.csv\")\n",
    "\n",
    "    def create_query_engine(self, vector_table_name):\n",
    "        vector_table = self.db.open_table(vector_table_name)\n",
    "        \n",
    "        def metadata_to_dict(metadata_str):\n",
    "            try:\n",
    "                return json.loads(metadata_str)\n",
    "            except json.JSONDecodeError:\n",
    "                return {\"raw_metadata\": metadata_str}\n",
    "\n",
    "        vector_store = LanceDBVectorStore(table=vector_table, metadata_decoder=metadata_to_dict)\n",
    "        vector_index = VectorStoreIndex.from_vector_store(vector_store)\n",
    "        vector_query_engine = vector_index.as_query_engine(\n",
    "            similarity_top_k=20,\n",
    "        )\n",
    "\n",
    "        query_engine_tool = QueryEngineTool(\n",
    "            query_engine=vector_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"vector_tool\",\n",
    "                description=\"Useful for retrieving general and specific information about the topic\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        tools = [query_engine_tool]\n",
    "\n",
    "        template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "        {tools}\n",
    "\n",
    "        Your task is to provide thorough and accurate responses to user queries.\n",
    "\n",
    "        Use the following format:\n",
    "\n",
    "        Question: the input question you must answer\n",
    "        Thought: you should always think about what to do\n",
    "        Action: the action to take, should be one of [{tool_names}]\n",
    "        Action Input: the input to the action\n",
    "        Observation: the result of the action\n",
    "        ... (this Thought/Action/Action Input/Observation can repeat 5 times)\n",
    "        Final Thought: I now know the final answer\n",
    "        Final Answer: the final answer to the original input question.\n",
    "        Begin!\n",
    "\n",
    "        Question: {input}\n",
    "        Thought:{agent_scratchpad}'''\n",
    "\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "        agent = ReActAgent.from_tools(\n",
    "            tools,\n",
    "            llm=self.llm,\n",
    "            verbose=True,\n",
    "            react_chat_prompt=prompt\n",
    "        )\n",
    "\n",
    "        return agent\n",
    "\n",
    "def main(filename, db_url=\"./.lancedb\"):\n",
    "    extractor = DocumentExtractor(filename=filename)\n",
    "    df_metadata = extractor.extract_metadata()\n",
    "\n",
    "    if df_metadata.empty:\n",
    "        print(f\"No valid metadata extracted from {filename}\")\n",
    "        return None\n",
    "\n",
    "    builder = DocumentBuilder(metadata=df_metadata)\n",
    "    df_enriched = builder.build(filename)\n",
    "    df_enriched = df_enriched.sort_values(by=\"page_number\")\n",
    "    df_enriched.to_csv(\"df_enriched.csv\")\n",
    "\n",
    "    index_handler = IndexHandler(metadata=df_enriched, db_url=db_url)\n",
    "    index_handler.add_documents_to_lancedb_table(df_enriched)\n",
    "\n",
    "    agent = index_handler.create_query_engine(\n",
    "        index_handler.vector_table_name\n",
    "    )\n",
    "\n",
    "    return agent\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    pdf_filename = \"iesc111.pdf\"\n",
    "    agent = main(pdf_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sarv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
